{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffdc9cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dgl.nn as dglnn\n",
    "from dgl import from_networkx\n",
    "import torch.nn as nn\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "from dgl.data.utils import load_graphs\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import socket\n",
    "import struct\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d97c7b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import *\n",
    "from torch_geometric.loader import NeighborSampler, NeighborLoader\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GATConv, ResGatedGraphConv, GATv2Conv, SAGEConv, GENConv, DeepGCNLayer, PairNorm, GINConv\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "import torch.nn.functional as F\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "pd.options.mode.use_inf_as_na = True\n",
    "from collections import Counter\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import pickle\n",
    "from torch.nn import LayerNorm, Linear, ReLU\n",
    "from torch_scatter import scatter\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.loader import RandomNodeSampler\n",
    "import math\n",
    "import copy\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.optim import lr_scheduler\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ade8a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, e_dim):\n",
    "        super(GATLayer, self).__init__()\n",
    "        self.w1 = nn.Linear(in_dim + e_dim, out_dim, bias=False)\n",
    "        self.w2 = nn.Linear(in_dim + out_dim, out_dim, bias=False)\n",
    "        self.w_att = nn.Linear(in_dim + out_dim, 1, bias=False)\n",
    "        self.reset_parameters()\n",
    "    def reset_parameters(self):\n",
    "        gain = nn.init.calculate_gain('relu')\n",
    "        nn.init.xavier_normal_(self.w1.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.w2.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.w_att.weight, gain=gain)\n",
    "    def edge_attention(self, edges):\n",
    "        z = torch.cat([edges.src['h'], edges.data['m']], -1)\n",
    "        a = self.w_att(z)\n",
    "        alpha = F.leaky_relu(a)\n",
    "        return {'e': alpha}\n",
    "    def msg1(self, edges):\n",
    "        return {'m': self.w1(th.cat([edges.src['h'], edges.data['h']], -1))}\n",
    "    \n",
    "    def message_func(self, edges):\n",
    "        return {'z': edges.data['m'], 'e': edges.data['e']}\n",
    "    def reduce_func(self, nodes):\n",
    "        alpha = F.softmax(nodes.mailbox['e'], dim=1) # 归一化每一条入边的注意力系数\n",
    "        h = torch.sum(alpha * nodes.mailbox['z'], dim=1)\n",
    "        return {'h_neigh': h}\n",
    "    def forward(self, g_dgl, hfeat, efeat):\n",
    "        with g_dgl.local_scope():\n",
    "            g = g_dgl\n",
    "            g.ndata['h'] = hfeat\n",
    "            g.edata['h'] = efeat\n",
    "            g.apply_edges(self.msg1)\n",
    "            g.apply_edges(self.edge_attention) # 为每一条边获得其注意力系数\n",
    "            g.update_all(self.message_func, self.reduce_func)\n",
    "            g.ndata['h'] = F.relu(self.w2(th.cat([g.ndata['h'], g.ndata['h_neigh']], -1)))\n",
    "            return g.ndata['h']\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, e_dim):\n",
    "        super().__init__()\n",
    "        self.layer1 = GATLayer(in_dim, hidden_dim, e_dim)\n",
    "        self.layer2 = GATLayer(hidden_dim, out_dim, e_dim)\n",
    "        self.pred = MLPPredictor(out_dim, 10)\n",
    "    def forward(self, g, nfeats, efeats):\n",
    "        nfeats = self.layer1(g, nfeats, efeats)\n",
    "        nfeats = self.layer2(g, nfeats, efeats)\n",
    "        return self.pred(g, nfeats)\n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, in_features, out_classes):\n",
    "        super().__init__()\n",
    "        self.W = nn.Linear(in_features * 2, out_classes)\n",
    "    def apply_edges(self, edges):\n",
    "        h_u = edges.src['h']\n",
    "        h_v = edges.dst['h']\n",
    "        score = self.W(th.cat([h_u, h_v], 1))\n",
    "        return {'score': score}\n",
    "    def forward(self, graph, h):\n",
    "        with graph.local_scope():\n",
    "            graph.ndata['h'] = h\n",
    "            graph.apply_edges(self.apply_edges)\n",
    "            return graph.edata['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "162caeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGELayer(nn.Module):\n",
    "    def __init__(self, ndim_in, edims, ndim_out, activation):\n",
    "        super(SAGELayer, self).__init__()\n",
    "        ### force to outut fix dimensions\n",
    "        self.W_msg = nn.Linear(ndim_in + edims, ndim_out)\n",
    "        ### apply weight\n",
    "        self.W_apply = nn.Linear(ndim_in + ndim_out, ndim_out)\n",
    "        self.activation = activation\n",
    "        self.embedector = torch.nn.Embedding(435887, 78)\n",
    "\n",
    "    def message_func(self, edges):\n",
    "        return {'m': self.W_msg(th.cat([edges.src['h'], edges.data['h']], 2))}\n",
    "\n",
    "    def forward(self, g_dgl, nfeats, efeats):\n",
    "        with g_dgl.local_scope():\n",
    "            g = g_dgl\n",
    "            g.ndata['h'] = nfeats\n",
    "            g.edata['h'] = efeats\n",
    "            # Eq4\n",
    "            g.update_all(self.message_func, fn.mean('m', 'h_neigh'))\n",
    "            # Eq5          \n",
    "            g.ndata['h'] = F.relu(self.W_apply(th.cat([g.ndata['h'], g.ndata['h_neigh']], 2)))\n",
    "            return g.ndata['h']\n",
    "\n",
    "\n",
    "class SAGE(nn.Module):\n",
    "    def __init__(self, ndim_in, ndim_out, edim, activation, dropout):\n",
    "        super(SAGE, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(SAGELayer(ndim_in, edim, 128, activation))\n",
    "        self.layers.append(SAGELayer(128, edim, ndim_out, activation))\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, g, nfeats, efeats):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if i != 0:\n",
    "                nfeats = self.dropout(nfeats)\n",
    "            nfeats = layer(g, nfeats, efeats)\n",
    "        return nfeats.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4c96fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = load_graphs(\"./mydata/unswnb15_train_data2.bin\")[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61a54443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=129739, num_edges=358047,\n",
       "      ndata_schemes={}\n",
       "      edata_schemes={'label': Scheme(shape=(), dtype=torch.int64), 'h': Scheme(shape=(40,), dtype=torch.float32)})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0fcb100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([     0,      1,      2,  ..., 129736, 129737, 129738])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5df7edd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'G' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-24cb5fc8bcec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_mask'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'G' is not defined"
     ]
    }
   ],
   "source": [
    "G.ndata['h'] = th.ones(G.num_nodes(), G.edata['h'].shape[1]) \n",
    "G.edata['train_mask'] = th.ones(len(G.edata['h']), dtype = th.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "606d5036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=406258, num_edges=1149379,\n",
       "      ndata_schemes={'h': Scheme(shape=(40,), dtype=torch.float32)}\n",
       "      edata_schemes={'label': Scheme(shape=(), dtype=torch.int64), 'h': Scheme(shape=(40,), dtype=torch.float32), 'train_mask': Scheme(shape=(), dtype=torch.bool)})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b85e41f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiaoyujie/anaconda3/envs/densegat2/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass classes=[0 1 2 3 4 5 6 7 8 9], y=[0 0 0 ... 0 0 0] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(G.edata['label'].cpu().numpy()),\n",
    "                                                 G.edata['label'].cpu().numpy())\n",
    "class_weights = th.FloatTensor(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "545bb72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbc14300",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = G.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a30f0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weights.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bcd81f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = G.ndata['h']\n",
    "edge_features = G.edata['h']\n",
    "\n",
    "edge_label = G.edata['label']\n",
    "train_mask = G.edata['train_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6773a806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([406258, 40])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_features.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b891ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = node_features.size(1)\n",
    "hidden_dim = 20\n",
    "out_dim = 10\n",
    "e_dim = in_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d66849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(in_dim, hidden_dim, out_dim, e_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41bbe809",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = th.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4027fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7c5eb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a831ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(pred, labels):\n",
    "    return (pred.argmax(1) == labels).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4ddd533",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.load('egat_unswnb15_model' + str(14900))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a8f97eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ffa61b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.12728941440582275 Epoch: 1  Training acc: 0.9509613513946533\n",
      "loss 0.1273033171892166 Epoch: 2  Training acc: 0.9506411552429199\n",
      "loss 0.12730267643928528 Epoch: 3  Training acc: 0.9508882761001587\n",
      "loss 0.12731419503688812 Epoch: 4  Training acc: 0.9506481289863586\n",
      "loss 0.1273181289434433 Epoch: 5  Training acc: 0.9509230256080627\n",
      "loss 0.12733949720859528 Epoch: 6  Training acc: 0.9509787559509277\n",
      "loss 0.12734583020210266 Epoch: 7  Training acc: 0.9505480527877808\n",
      "loss 0.12734884023666382 Epoch: 8  Training acc: 0.9509891867637634\n",
      "loss 0.12734565138816833 Epoch: 9  Training acc: 0.9505001902580261\n",
      "loss 0.12739503383636475 Epoch: 10  Training acc: 0.9509230256080627\n",
      "loss 0.12739382684230804 Epoch: 11  Training acc: 0.9502400755882263\n",
      "loss 0.1273752748966217 Epoch: 12  Training acc: 0.9509561061859131\n",
      "loss 0.12736351788043976 Epoch: 13  Training acc: 0.9506446123123169\n",
      "loss 0.12737911939620972 Epoch: 14  Training acc: 0.9508969783782959\n",
      "loss 0.12736204266548157 Epoch: 15  Training acc: 0.9506420493125916\n",
      "loss 0.12737242877483368 Epoch: 16  Training acc: 0.9508847594261169\n",
      "loss 0.1273653656244278 Epoch: 17  Training acc: 0.9507681727409363\n",
      "loss 0.12735936045646667 Epoch: 18  Training acc: 0.9508029818534851\n",
      "loss 0.12732765078544617 Epoch: 19  Training acc: 0.9506272673606873\n",
      "loss 0.12730813026428223 Epoch: 20  Training acc: 0.9508987069129944\n",
      "loss 0.1272803544998169 Epoch: 21  Training acc: 0.9506829380989075\n",
      "loss 0.1272825002670288 Epoch: 22  Training acc: 0.9509891867637634\n",
      "loss 0.12726625800132751 Epoch: 23  Training acc: 0.9509299993515015\n",
      "loss 0.12727400660514832 Epoch: 24  Training acc: 0.9506898522377014\n",
      "loss 0.12728914618492126 Epoch: 25  Training acc: 0.9508777856826782\n",
      "loss 0.12729096412658691 Epoch: 26  Training acc: 0.9506881237030029\n",
      "loss 0.127299502491951 Epoch: 27  Training acc: 0.9508760571479797\n",
      "loss 0.12729902565479279 Epoch: 28  Training acc: 0.9507037997245789\n",
      "loss 0.12730880081653595 Epoch: 29  Training acc: 0.9508012533187866\n",
      "loss 0.1273236870765686 Epoch: 30  Training acc: 0.9507507681846619\n",
      "loss 0.12731409072875977 Epoch: 31  Training acc: 0.9505184888839722\n",
      "loss 0.1272958666086197 Epoch: 32  Training acc: 0.9510309100151062\n",
      "loss 0.12729386985301971 Epoch: 33  Training acc: 0.9505541324615479\n",
      "loss 0.12727855145931244 Epoch: 34  Training acc: 0.9509630799293518\n",
      "loss 0.12727724015712738 Epoch: 35  Training acc: 0.9509822130203247\n",
      "loss 0.12728163599967957 Epoch: 36  Training acc: 0.9506324529647827\n",
      "loss 0.12727421522140503 Epoch: 37  Training acc: 0.9509804844856262\n",
      "loss 0.12727931141853333 Epoch: 38  Training acc: 0.9505680799484253\n",
      "loss 0.1272689700126648 Epoch: 39  Training acc: 0.9510170221328735\n",
      "loss 0.12727418541908264 Epoch: 40  Training acc: 0.9506011605262756\n",
      "loss 0.12726996839046478 Epoch: 41  Training acc: 0.9506394267082214\n",
      "loss 0.12727917730808258 Epoch: 42  Training acc: 0.9509004354476929\n",
      "loss 0.12727059423923492 Epoch: 43  Training acc: 0.9506350755691528\n",
      "loss 0.1272786557674408 Epoch: 44  Training acc: 0.9508760571479797\n",
      "loss 0.12727884948253632 Epoch: 45  Training acc: 0.9506551027297974\n",
      "loss 0.12728016078472137 Epoch: 46  Training acc: 0.9509335160255432\n",
      "loss 0.1272761970758438 Epoch: 47  Training acc: 0.9510048627853394\n",
      "loss 0.12727440893650055 Epoch: 48  Training acc: 0.9505428671836853\n",
      "loss 0.12727168202400208 Epoch: 49  Training acc: 0.9510274529457092\n",
      "loss 0.1272738128900528 Epoch: 50  Training acc: 0.9505837559700012\n",
      "loss 0.12727242708206177 Epoch: 51  Training acc: 0.9509613513946533\n",
      "loss 0.1272754818201065 Epoch: 52  Training acc: 0.9506359100341797\n",
      "loss 0.12728020548820496 Epoch: 53  Training acc: 0.9509543776512146\n",
      "loss 0.12729451060295105 Epoch: 54  Training acc: 0.9506150484085083\n",
      "loss 0.12731505930423737 Epoch: 55  Training acc: 0.9509787559509277\n",
      "loss 0.1273248791694641 Epoch: 56  Training acc: 0.9506272673606873\n",
      "loss 0.12734979391098022 Epoch: 57  Training acc: 0.9509074091911316\n",
      "loss 0.1273682564496994 Epoch: 58  Training acc: 0.9506707191467285\n",
      "loss 0.12739738821983337 Epoch: 59  Training acc: 0.9509700536727905\n",
      "loss 0.1274096518754959 Epoch: 60  Training acc: 0.9505941867828369\n",
      "loss 0.12743495404720306 Epoch: 61  Training acc: 0.9509978890419006\n",
      "loss 0.12739814817905426 Epoch: 62  Training acc: 0.9505802392959595\n",
      "loss 0.1273781657218933 Epoch: 63  Training acc: 0.9509474039077759\n",
      "loss 0.12735457718372345 Epoch: 64  Training acc: 0.9506289958953857\n",
      "loss 0.12731903791427612 Epoch: 65  Training acc: 0.9509595632553101\n",
      "loss 0.1272973269224167 Epoch: 66  Training acc: 0.9510048627853394\n",
      "loss 0.1272791028022766 Epoch: 67  Training acc: 0.9505437016487122\n",
      "loss 0.127261221408844 Epoch: 68  Training acc: 0.951034426689148\n",
      "loss 0.12726138532161713 Epoch: 69  Training acc: 0.9505802392959595\n",
      "loss 0.1272655576467514 Epoch: 70  Training acc: 0.9510378837585449\n",
      "loss 0.12728261947631836 Epoch: 71  Training acc: 0.9508951902389526\n",
      "loss 0.12730558216571808 Epoch: 72  Training acc: 0.95066899061203\n",
      "loss 0.1273200362920761 Epoch: 73  Training acc: 0.9509161114692688\n",
      "loss 0.12732979655265808 Epoch: 74  Training acc: 0.95061856508255\n",
      "loss 0.12732785940170288 Epoch: 75  Training acc: 0.9509404301643372\n",
      "loss 0.1273169219493866 Epoch: 76  Training acc: 0.9506359100341797\n",
      "loss 0.12729628384113312 Epoch: 77  Training acc: 0.950975239276886\n",
      "loss 0.12729665637016296 Epoch: 78  Training acc: 0.9509456753730774\n",
      "loss 0.12730315327644348 Epoch: 79  Training acc: 0.9506551027297974\n",
      "loss 0.12734396755695343 Epoch: 80  Training acc: 0.9508334398269653\n",
      "loss 0.12733016908168793 Epoch: 81  Training acc: 0.9503244757652283\n",
      "loss 0.12735523283481598 Epoch: 82  Training acc: 0.9508795738220215\n",
      "loss 0.12731768190860748 Epoch: 83  Training acc: 0.9506881237030029\n",
      "loss 0.12731346487998962 Epoch: 84  Training acc: 0.9508743286132812\n",
      "loss 0.1273098886013031 Epoch: 85  Training acc: 0.9506776928901672\n",
      "loss 0.1273006647825241 Epoch: 86  Training acc: 0.9508482217788696\n",
      "loss 0.12730523943901062 Epoch: 87  Training acc: 0.9509926438331604\n",
      "loss 0.12728317081928253 Epoch: 88  Training acc: 0.9505193829536438\n",
      "loss 0.12729419767856598 Epoch: 89  Training acc: 0.9510170221328735\n",
      "loss 0.12726999819278717 Epoch: 90  Training acc: 0.9505437016487122\n",
      "loss 0.12726309895515442 Epoch: 91  Training acc: 0.9510100483894348\n",
      "loss 0.12726256251335144 Epoch: 92  Training acc: 0.9509691596031189\n",
      "loss 0.12725265324115753 Epoch: 93  Training acc: 0.9505437016487122\n",
      "loss 0.12727367877960205 Epoch: 94  Training acc: 0.9509996175765991\n",
      "loss 0.12727834284305573 Epoch: 95  Training acc: 0.9506237506866455\n",
      "loss 0.1272539496421814 Epoch: 96  Training acc: 0.9509996175765991\n",
      "loss 0.1272611767053604 Epoch: 97  Training acc: 0.9509038925170898\n",
      "loss 0.1272650510072708 Epoch: 98  Training acc: 0.9506950974464417\n",
      "loss 0.1272636353969574 Epoch: 99  Training acc: 0.9508934617042542\n",
      "loss 0.12726238369941711 Epoch: 100  Training acc: 0.9507142305374146\n",
      "loss 0.12726326286792755 Epoch: 101  Training acc: 0.9509369730949402\n",
      "loss 0.1272546350955963 Epoch: 102  Training acc: 0.9506863951683044\n",
      "loss 0.12725895643234253 Epoch: 103  Training acc: 0.95088130235672\n",
      "loss 0.12726810574531555 Epoch: 104  Training acc: 0.9510900974273682\n",
      "loss 0.12728367745876312 Epoch: 105  Training acc: 0.950484573841095\n",
      "loss 0.127284973859787 Epoch: 106  Training acc: 0.951022207736969\n",
      "loss 0.12727601826190948 Epoch: 107  Training acc: 0.9505437016487122\n",
      "loss 0.1272655725479126 Epoch: 108  Training acc: 0.9510648846626282\n",
      "loss 0.12727631628513336 Epoch: 109  Training acc: 0.9508726000785828\n",
      "loss 0.1273256093263626 Epoch: 110  Training acc: 0.9507212042808533\n",
      "loss 0.12730009853839874 Epoch: 111  Training acc: 0.950822114944458\n",
      "loss 0.1272915154695511 Epoch: 112  Training acc: 0.9506881237030029\n",
      "loss 0.12731632590293884 Epoch: 113  Training acc: 0.9505367279052734\n",
      "loss 0.1272777020931244 Epoch: 114  Training acc: 0.9510361552238464\n",
      "loss 0.12729519605636597 Epoch: 115  Training acc: 0.9508882761001587\n",
      "loss 0.12726952135562897 Epoch: 116  Training acc: 0.9507412314414978\n",
      "loss 0.12726089358329773 Epoch: 117  Training acc: 0.9509265422821045\n",
      "loss 0.12726537883281708 Epoch: 118  Training acc: 0.9506446123123169\n",
      "loss 0.12724268436431885 Epoch: 119  Training acc: 0.9509891867637634\n",
      "loss 0.12725310027599335 Epoch: 120  Training acc: 0.9506359100341797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.1272467076778412 Epoch: 121  Training acc: 0.9510030746459961\n",
      "loss 0.12723949551582336 Epoch: 122  Training acc: 0.9509491324424744\n",
      "loss 0.12724502384662628 Epoch: 123  Training acc: 0.9506829380989075\n",
      "loss 0.1272590011358261 Epoch: 124  Training acc: 0.9509056210517883\n",
      "loss 0.12727366387844086 Epoch: 125  Training acc: 0.9507229328155518\n",
      "loss 0.12726865708827972 Epoch: 126  Training acc: 0.9508203864097595\n",
      "loss 0.12726418673992157 Epoch: 127  Training acc: 0.951065719127655\n",
      "loss 0.12728199362754822 Epoch: 128  Training acc: 0.9505175948143005\n",
      "loss 0.127256378531456 Epoch: 129  Training acc: 0.9510692358016968\n",
      "loss 0.12726198136806488 Epoch: 130  Training acc: 0.9509335160255432\n",
      "loss 0.12725910544395447 Epoch: 131  Training acc: 0.9507107734680176\n",
      "loss 0.1272473782300949 Epoch: 132  Training acc: 0.9508830308914185\n",
      "loss 0.127253457903862 Epoch: 133  Training acc: 0.9506620168685913\n",
      "loss 0.12724551558494568 Epoch: 134  Training acc: 0.950869083404541\n",
      "loss 0.12724795937538147 Epoch: 135  Training acc: 0.9506881237030029\n",
      "loss 0.12724943459033966 Epoch: 136  Training acc: 0.9509422183036804\n",
      "loss 0.12724238634109497 Epoch: 137  Training acc: 0.950728178024292\n",
      "loss 0.12724275887012482 Epoch: 138  Training acc: 0.9509178400039673\n",
      "loss 0.12724152207374573 Epoch: 139  Training acc: 0.9506707191467285\n",
      "loss 0.1272413730621338 Epoch: 140  Training acc: 0.9508882761001587\n",
      "loss 0.12724322080612183 Epoch: 141  Training acc: 0.9507437944412231\n",
      "loss 0.12724123895168304 Epoch: 142  Training acc: 0.950865626335144\n",
      "loss 0.12724879384040833 Epoch: 143  Training acc: 0.9506881237030029\n",
      "loss 0.12724438309669495 Epoch: 144  Training acc: 0.9505559206008911\n",
      "loss 0.12724973261356354 Epoch: 145  Training acc: 0.9510761499404907\n",
      "loss 0.1272481232881546 Epoch: 146  Training acc: 0.9508830308914185\n",
      "loss 0.1272495537996292 Epoch: 147  Training acc: 0.9507090449333191\n",
      "loss 0.12726344168186188 Epoch: 148  Training acc: 0.9508847594261169\n",
      "loss 0.12727411091327667 Epoch: 149  Training acc: 0.9507246613502502\n",
      "loss 0.12731245160102844 Epoch: 150  Training acc: 0.9509456753730774\n",
      "loss 0.12735755741596222 Epoch: 151  Training acc: 0.9506863951683044\n",
      "loss 0.12745127081871033 Epoch: 152  Training acc: 0.9508795738220215\n",
      "loss 0.12755800783634186 Epoch: 153  Training acc: 0.9502826929092407\n",
      "loss 0.12773799896240234 Epoch: 154  Training acc: 0.950869083404541\n",
      "loss 0.12775644659996033 Epoch: 155  Training acc: 0.950581967830658\n",
      "loss 0.12784594297409058 Epoch: 156  Training acc: 0.9508621692657471\n",
      "loss 0.1276790201663971 Epoch: 157  Training acc: 0.9504984617233276\n",
      "loss 0.12752236425876617 Epoch: 158  Training acc: 0.9506080746650696\n",
      "loss 0.1273406744003296 Epoch: 159  Training acc: 0.9509021639823914\n",
      "loss 0.12729354202747345 Epoch: 160  Training acc: 0.9507072567939758\n",
      "loss 0.12736262381076813 Epoch: 161  Training acc: 0.950950026512146\n",
      "loss 0.1274048238992691 Epoch: 162  Training acc: 0.9506359100341797\n",
      "loss 0.12748554348945618 Epoch: 163  Training acc: 0.9509943723678589\n",
      "loss 0.12745682895183563 Epoch: 164  Training acc: 0.9509630799293518\n",
      "loss 0.12739558517932892 Epoch: 165  Training acc: 0.9505680799484253\n",
      "loss 0.1273041069507599 Epoch: 166  Training acc: 0.9509891867637634\n",
      "loss 0.12726111710071564 Epoch: 167  Training acc: 0.9505906701087952\n",
      "loss 0.12727169692516327 Epoch: 168  Training acc: 0.9509648084640503\n",
      "loss 0.1273215115070343 Epoch: 169  Training acc: 0.9509299993515015\n",
      "loss 0.12737800180912018 Epoch: 170  Training acc: 0.950715959072113\n",
      "loss 0.1273634135723114 Epoch: 171  Training acc: 0.9509387016296387\n",
      "loss 0.12732234597206116 Epoch: 172  Training acc: 0.9505976438522339\n",
      "loss 0.1272500902414322 Epoch: 173  Training acc: 0.9509961605072021\n",
      "loss 0.12724916636943817 Epoch: 174  Training acc: 0.9509613513946533\n",
      "loss 0.12728185951709747 Epoch: 175  Training acc: 0.9510100483894348\n",
      "loss 0.12728284299373627 Epoch: 176  Training acc: 0.9509012699127197\n",
      "loss 0.12730547785758972 Epoch: 177  Training acc: 0.9510291814804077\n",
      "loss 0.1272922158241272 Epoch: 178  Training acc: 0.9505472183227539\n",
      "loss 0.12728023529052734 Epoch: 179  Training acc: 0.9509787559509277\n",
      "loss 0.12723664939403534 Epoch: 180  Training acc: 0.9506063461303711\n",
      "loss 0.12724244594573975 Epoch: 181  Training acc: 0.9510326981544495\n",
      "loss 0.12723590433597565 Epoch: 182  Training acc: 0.9509961605072021\n",
      "loss 0.12724436819553375 Epoch: 183  Training acc: 0.9509308934211731\n",
      "loss 0.1272611767053604 Epoch: 184  Training acc: 0.9506638050079346\n",
      "loss 0.12726201117038727 Epoch: 185  Training acc: 0.9509682655334473\n",
      "loss 0.12726522982120514 Epoch: 186  Training acc: 0.9506742358207703\n",
      "loss 0.12725168466567993 Epoch: 187  Training acc: 0.9509143233299255\n",
      "loss 0.12723292410373688 Epoch: 188  Training acc: 0.9506542086601257\n",
      "loss 0.12724372744560242 Epoch: 189  Training acc: 0.9509352445602417\n",
      "loss 0.12725473940372467 Epoch: 190  Training acc: 0.9510709643363953\n",
      "loss 0.12726972997188568 Epoch: 191  Training acc: 0.9505854845046997\n",
      "loss 0.1272708624601364 Epoch: 192  Training acc: 0.9510135054588318\n",
      "loss 0.12727636098861694 Epoch: 193  Training acc: 0.950575053691864\n",
      "loss 0.12724895775318146 Epoch: 194  Training acc: 0.9510448575019836\n",
      "loss 0.1272444725036621 Epoch: 195  Training acc: 0.9510013461112976\n",
      "loss 0.1272314339876175 Epoch: 196  Training acc: 0.9506324529647827\n",
      "loss 0.12723690271377563 Epoch: 197  Training acc: 0.9509839415550232\n",
      "loss 0.12723642587661743 Epoch: 198  Training acc: 0.9505854845046997\n",
      "loss 0.1272325962781906 Epoch: 199  Training acc: 0.9509909152984619\n",
      "loss 0.1272347867488861 Epoch: 200  Training acc: 0.95061856508255\n",
      "loss 0.12723124027252197 Epoch: 201  Training acc: 0.9510204792022705\n",
      "loss 0.12723194062709808 Epoch: 202  Training acc: 0.9509787559509277\n",
      "loss 0.12722845375537872 Epoch: 203  Training acc: 0.95066899061203\n",
      "loss 0.12722253799438477 Epoch: 204  Training acc: 0.9510048627853394\n",
      "loss 0.12722180783748627 Epoch: 205  Training acc: 0.9506707191467285\n",
      "loss 0.12722784280776978 Epoch: 206  Training acc: 0.9510170221328735\n",
      "loss 0.1272178739309311 Epoch: 207  Training acc: 0.950625479221344\n",
      "loss 0.12722313404083252 Epoch: 208  Training acc: 0.9509996175765991\n",
      "loss 0.1272236406803131 Epoch: 209  Training acc: 0.95066899061203\n",
      "loss 0.12722308933734894 Epoch: 210  Training acc: 0.9509578347206116\n",
      "loss 0.1272292137145996 Epoch: 211  Training acc: 0.951015293598175\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-1b17bb64b5a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m15000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/densegat2/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-5f94e9029e0d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, nfeats, efeats)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLPPredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mefeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mnfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mefeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mnfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mefeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/densegat2/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-5f94e9029e0d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g_dgl, hfeat, efeat)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_attention\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 为每一条边获得其注意力系数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'h_neigh'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/densegat2/lib/python3.6/site-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36mupdate_all\u001b[0;34m(self, message_func, reduce_func, apply_node_func, etype)\u001b[0m\n\u001b[1;32m   4893\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetagraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4894\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0metype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4895\u001b[0;31m             \u001b[0mndata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage_passing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_node_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4896\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_builtin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mndata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4897\u001b[0m                 \u001b[0;31m# Replace infinity with zero for isolated nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/densegat2/lib/python3.6/site-packages/dgl/core.py\u001b[0m in \u001b[0;36mmessage_passing\u001b[0;34m(g, mfunc, rfunc, afunc)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0morig_nid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdstdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m             \u001b[0mndata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minvoke_udf_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsgdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_nid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morig_nid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m     \u001b[0;31m# apply phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mafunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/densegat2/lib/python3.6/site-packages/dgl/core.py\u001b[0m in \u001b[0;36minvoke_udf_reduce\u001b[0;34m(graph, func, msgdata, orig_nid)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;31m# order the incoming edges per node by edge ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0meid_bkt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzerocopy_to_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_bkt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'eid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meid_bkt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdeg\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_bkt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0meid_bkt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meid_bkt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_bkt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/densegat2/lib/python3.6/site-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mzerocopy_to_numpy\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mzerocopy_to_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;31m# NOTE: not zerocopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mzerocopy_from_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/densegat2/lib/python3.6/site-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcopy_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "for epoch in range(1 ,15000):\n",
    "    pred = model(G, node_features, edge_features)\n",
    "    loss = criterion(pred[train_mask], edge_label[train_mask])\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    print('loss',loss.item(),'Epoch:', epoch ,' Training acc:', compute_accuracy(pred[train_mask], edge_label[train_mask]))\n",
    "    if epoch % 100 == 0:\n",
    "        torch.save(model.state_dict(), 'egat_unswnb15_model' + str(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "032b1b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cpu')\n",
    "cm, cr = test(G_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "096f5488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9928    0.9878    0.9903    299832\n",
      "           1     0.5859    0.8352    0.6887     26716\n",
      "           2     0.9179    0.6978    0.7929      8392\n",
      "           3     0.3855    0.1492    0.2151      9812\n",
      "           4     0.9918    0.9789    0.9853    129288\n",
      "           5     0.5725    0.8190    0.6739       906\n",
      "           6     0.6939    0.7990    0.7427     14548\n",
      "           7     0.0000    0.0000    0.0000       104\n",
      "           8     0.3667    0.0157    0.0302      1398\n",
      "           9     0.0000    0.0000    0.0000      1606\n",
      "\n",
      "    accuracy                         0.9435    492602\n",
      "   macro avg     0.5507    0.5283    0.5119    492602\n",
      "weighted avg     0.9423    0.9435    0.9398    492602\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9435bb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9929    0.9880    0.9904    299832\n",
      "           1     0.5889    0.8215    0.6860     26716\n",
      "           2     0.8954    0.6995    0.7854      8392\n",
      "           3     0.3807    0.2532    0.3041      9812\n",
      "           4     0.9929    0.9789    0.9858    129288\n",
      "           5     0.5664    0.8102    0.6667       906\n",
      "           6     0.7438    0.7576    0.7507     14548\n",
      "           7     0.0000    0.0000    0.0000       104\n",
      "           8     0.4815    0.0186    0.0358      1398\n",
      "           9     0.0079    0.0012    0.0022      1606\n",
      "\n",
      "    accuracy                         0.9437    492602\n",
      "   macro avg     0.5650    0.5329    0.5207    492602\n",
      "weighted avg     0.9441    0.9437    0.9417    492602\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5cba47d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9922    0.9882    0.9902    299832\n",
      "           1     0.5568    0.8932    0.6860     26716\n",
      "           2     0.8696    0.6992    0.7752      8392\n",
      "           3     0.3178    0.0222    0.0415      9812\n",
      "           4     0.9938    0.9783    0.9860    129288\n",
      "           5     0.5613    0.8190    0.6661       906\n",
      "           6     0.7373    0.7612    0.7491     14548\n",
      "           7     0.0000    0.0000    0.0000       104\n",
      "           8     0.5000    0.0172    0.0332      1398\n",
      "           9     0.0667    0.0012    0.0024      1606\n",
      "\n",
      "    accuracy                         0.9431    492602\n",
      "   macro avg     0.5595    0.5180    0.4930    492602\n",
      "weighted avg     0.9405    0.9431    0.9362    492602\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d338b400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9892    0.9879    0.9886    299832\n",
      "           1     0.5592    0.8571    0.6768     26716\n",
      "           2     0.9335    0.7064    0.8042      8392\n",
      "           3     0.3923    0.0136    0.0262      9812\n",
      "           4     0.9944    0.9774    0.9858    129288\n",
      "           5     0.5639    0.7550    0.6456       906\n",
      "           6     0.6808    0.8043    0.7374     14548\n",
      "           7     0.0000    0.0000    0.0000       104\n",
      "           8     0.0000    0.0000    0.0000      1398\n",
      "           9     0.0909    0.0012    0.0025      1606\n",
      "\n",
      "    accuracy                         0.9418    492602\n",
      "   macro avg     0.5204    0.5103    0.4867    492602\n",
      "weighted avg     0.9386    0.9418    0.9344    492602\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ded0efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9964    0.9875    0.9919    299832\n",
      "           1     0.5472    0.9163    0.6852     26716\n",
      "           2     0.9653    0.6372    0.7676      8392\n",
      "           3     0.8125    0.0026    0.0053      9812\n",
      "           4     0.9938    0.9766    0.9851    129288\n",
      "           5     0.5728    0.5210    0.5457       906\n",
      "           6     0.6557    0.7771    0.7112     14548\n",
      "           7     0.0000    0.0000    0.0000       104\n",
      "           8     0.0000    0.0000    0.0000      1398\n",
      "           9     0.3030    0.0062    0.0122      1606\n",
      "\n",
      "    accuracy                         0.9419    492602\n",
      "   macro avg     0.5847    0.4824    0.4704    492602\n",
      "weighted avg     0.9510    0.9419    0.9347    492602\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e79cf546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(G_test, model):\n",
    "    test_node_features = G_test.ndata['h']\n",
    "    test_edge_features = G_test.edata['h']\n",
    "    y_true = G_test.edata['label'].detach().numpy()\n",
    "    pred = model(G_test, test_node_features, test_edge_features)\n",
    "    y_pred = pred.detach().numpy()\n",
    "    y_pred = np.argmax(y_pred, -1)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cr = classification_report(y_true, y_pred, digits=4)\n",
    "    return cm, cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46348949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=406258, num_edges=1149379,\n",
       "      ndata_schemes={'h': Scheme(shape=(40,), dtype=torch.float32)}\n",
       "      edata_schemes={'label': Scheme(shape=(), dtype=torch.int64), 'h': Scheme(shape=(40,), dtype=torch.float32), 'train_mask': Scheme(shape=(), dtype=torch.bool)})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc7eb1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_test = load_graphs(\"./mydata/unswnb15_test_data2.bin\")[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8602eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_test.ndata['h'] = th.ones(G_test.num_nodes(), G_test.edata['h'].shape[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a95837c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 299832,\n",
       "         4: 129288,\n",
       "         1: 26716,\n",
       "         3: 9812,\n",
       "         2: 8392,\n",
       "         9: 1606,\n",
       "         6: 14548,\n",
       "         7: 104,\n",
       "         8: 1398,\n",
       "         5: 906})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(G_test.edata['label'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afe5021e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 699583,\n",
       "         4: 301674,\n",
       "         1: 62334,\n",
       "         3: 22894,\n",
       "         2: 19582,\n",
       "         6: 33944,\n",
       "         8: 3260,\n",
       "         9: 3748,\n",
       "         7: 244,\n",
       "         5: 2116})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(G.edata['label'].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e29cd994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=406258, num_edges=1149379,\n",
       "      ndata_schemes={'h': Scheme(shape=(40,), dtype=torch.float32)}\n",
       "      edata_schemes={'label': Scheme(shape=(), dtype=torch.int64), 'h': Scheme(shape=(40,), dtype=torch.float32), 'train_mask': Scheme(shape=(), dtype=torch.bool)})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aea37f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1149379, 40])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.edata['h'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20360941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1355f98d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caf19cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8c9dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bcd55d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc3d10a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791a3c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bebe4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01fddd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, in_dim , out_dim):\n",
    "        super(GATLayer, self).__init__()\n",
    "        self.W = nn.Linear(in_dim, out_dim, bias=False)\n",
    "        self.attn_fc = nn.Linear(3 * out_dim, 1, bias=False)\n",
    "        self.reset_parameters()\n",
    "    def reset_parameters(self):\n",
    "        gain = nn.init.calculate_gain('relu')\n",
    "        nn.init.xavier_normal_(self.W.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.attn_fc.weight, gain=gain)\n",
    "    def edge_attention(self, edges):\n",
    "        z = torch.cat([edges.src['z'], edges.dst['z'], edges.data['z']], -1)\n",
    "        a = self.attn_fc(z)\n",
    "        alpha = F.leaky_relu(a)\n",
    "        return {'e': alpha}\n",
    "    def message_func(self, edges):\n",
    "        return {'z': edges.src['z'], 'e': edges.data['e'] ,'m': edges.data['z']}\n",
    "    def reduce_func(self, nodes):\n",
    "        alpha = F.softmax(nodes.mailbox['e'], dim=1) # 归一化每一条入边的注意力系数\n",
    "        h = torch.sum(alpha * nodes.mailbox['m'], dim=1)\n",
    "        return {'h': F.relu(h)}\n",
    "    def forward(self, g_dgl, hfeat, efeat):\n",
    "        with g_dgl.local_scope():\n",
    "            g = g_dgl\n",
    "            z1 = self.W(hfeat)\n",
    "            z2 = self.W(efeat)\n",
    "            g.ndata['z'] = z1 # 每个节点的特征\n",
    "            g.edata['z'] = z2 # 每条边的特征\n",
    "            g.apply_edges(self.edge_attention) # 为每一条边获得其注意力系数\n",
    "            g.update_all(self.message_func, self.reduce_func)\n",
    "            return g.ndata['h'], g.edata['z']\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.layer1 = GATLayer(in_dim, hidden_dim)\n",
    "        self.layer2 = GATLayer(hidden_dim, out_dim)\n",
    "        self.pred = MLPPredictor(out_dim, 5)\n",
    "    def forward(self, g, nfeats, efeats):\n",
    "        nfeats, efeats = self.layer1(g, nfeats, efeats)\n",
    "#         nfeats, efeats = self.layer2(g, nfeats, efeats)\n",
    "        return self.pred(g, nfeats)\n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, in_features, out_classes):\n",
    "        super().__init__()\n",
    "        self.W = nn.Linear(in_features * 2, out_classes)\n",
    "    def apply_edges(self, edges):\n",
    "        h_u = edges.src['h']\n",
    "        h_v = edges.dst['h']\n",
    "        score = self.W(th.cat([h_u, h_v], 1))\n",
    "        return {'score': score}\n",
    "    def forward(self, graph, h):\n",
    "        with graph.local_scope():\n",
    "            graph.ndata['h'] = h\n",
    "            graph.apply_edges(self.apply_edges)\n",
    "            return graph.edata['score']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
