{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffdc9cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dgl.nn as dglnn\n",
    "from dgl import from_networkx\n",
    "import torch.nn as nn\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "from dgl.data.utils import load_graphs\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import socket\n",
    "import struct\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d97c7b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import *\n",
    "from torch_geometric.loader import NeighborSampler, NeighborLoader\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GATConv, ResGatedGraphConv, GATv2Conv, SAGEConv, GENConv, DeepGCNLayer, PairNorm, GINConv\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "import torch.nn.functional as F\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "pd.options.mode.use_inf_as_na = True\n",
    "from collections import Counter\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import pickle\n",
    "from torch.nn import LayerNorm, Linear, ReLU\n",
    "from torch_scatter import scatter\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.loader import RandomNodeSampler\n",
    "import math\n",
    "import copy\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.optim import lr_scheduler\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8599ef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, e_dim):\n",
    "        super(GATLayer, self).__init__()\n",
    "        self.w1 = nn.Linear(in_dim + e_dim, out_dim, bias=False)\n",
    "        self.w2 = nn.Linear(in_dim + out_dim, out_dim, bias=False)\n",
    "        self.w_att = nn.Linear(in_dim + out_dim, 1, bias=False)\n",
    "        self.reset_parameters()\n",
    "    def reset_parameters(self):\n",
    "        gain = nn.init.calculate_gain('relu')\n",
    "        nn.init.xavier_normal_(self.w1.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.w2.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.w_att.weight, gain=gain)\n",
    "    def edge_attention(self, edges):\n",
    "        z = torch.cat([edges.src['h'], edges.data['m']], -1)\n",
    "        a = self.w_att(z)\n",
    "        alpha = F.leaky_relu(a)\n",
    "        return {'e': alpha}\n",
    "    def msg1(self, edges):\n",
    "        return {'m': self.w1(th.cat([edges.src['h'], edges.data['h']], -1))}\n",
    "    \n",
    "    def message_func(self, edges):\n",
    "        return {'z': edges.data['m'], 'e': edges.data['e']}\n",
    "    def reduce_func(self, nodes):\n",
    "        alpha = F.softmax(nodes.mailbox['e'], dim=1) # 归一化每一条入边的注意力系数\n",
    "        h = torch.sum(alpha * nodes.mailbox['z'], dim=1)\n",
    "        return {'h_neigh': h}\n",
    "    def forward(self, g_dgl, hfeat, efeat):\n",
    "        with g_dgl.local_scope():\n",
    "            g = g_dgl\n",
    "            g.ndata['h'] = hfeat\n",
    "            g.edata['h'] = efeat\n",
    "            g.apply_edges(self.msg1)\n",
    "            g.apply_edges(self.edge_attention) # 为每一条边获得其注意力系数\n",
    "            g.update_all(self.message_func, self.reduce_func)\n",
    "            g.ndata['h'] = F.relu(self.w2(th.cat([g.ndata['h'], g.ndata['h_neigh']], -1)))\n",
    "            return g.ndata['h']\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, e_dim):\n",
    "        super().__init__()\n",
    "        self.layer1 = GATLayer(in_dim, hidden_dim, e_dim)\n",
    "        self.layer2 = GATLayer(hidden_dim, out_dim, e_dim)\n",
    "        self.pred = MLPPredictor(out_dim, 5)\n",
    "    def forward(self, g, nfeats, efeats):\n",
    "        nfeats = self.layer1(g, nfeats, efeats)\n",
    "        nfeats = self.layer2(g, nfeats, efeats)\n",
    "        return self.pred(g, nfeats)\n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, in_features, out_classes):\n",
    "        super().__init__()\n",
    "        self.W = nn.Linear(in_features * 2, out_classes)\n",
    "    def apply_edges(self, edges):\n",
    "        h_u = edges.src['h']\n",
    "        h_v = edges.dst['h']\n",
    "        score = self.W(th.cat([h_u, h_v], 1))\n",
    "        return {'score': score}\n",
    "    def forward(self, graph, h):\n",
    "        with graph.local_scope():\n",
    "            graph.ndata['h'] = h\n",
    "            graph.apply_edges(self.apply_edges)\n",
    "            return graph.edata['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d564e1bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4c96fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = load_graphs(\"./botlot/All features/bot_data_rus.bin\")[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5df7edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.ndata['h'] = th.ones(G.num_nodes(), G.edata['h'].shape[1]) \n",
    "G.edata['train_mask'] = th.ones(len(G.edata['h']), dtype= th.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "606d5036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=261186, num_edges=514292,\n",
       "      ndata_schemes={'h': Scheme(shape=(52,), dtype=torch.float32)}\n",
       "      edata_schemes={'train_mask': Scheme(shape=(), dtype=torch.bool), 'h': Scheme(shape=(52,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64)})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b85e41f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiaoyujie/anaconda3/envs/densegat2/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass classes=[0 1 2 3 4], y=[1 1 1 ... 1 1 0] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(G.edata['label'].cpu().numpy()),\n",
    "                                                 G.edata['label'].cpu().numpy())\n",
    "class_weights = th.FloatTensor(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87a16dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e486bf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = G.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a53b708",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weights.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bcd81f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = G.ndata['h']\n",
    "edge_features = G.edata['h']\n",
    "\n",
    "edge_label = G.edata['label']\n",
    "train_mask = G.edata['train_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b891ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = 52\n",
    "hidden_dim = 20\n",
    "out_dim = 10\n",
    "e_dim = 52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d66849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(in_dim, hidden_dim, out_dim, e_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41bbe809",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = th.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4027fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73040b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b8e3346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(pred, labels):\n",
    "    return (pred.argmax(1) == labels).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ffa61b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.0003645187243819237 Epoch: 9300  Training acc: 0.9999319911003113\n",
      "loss 0.0003376924723852426 Epoch: 9400  Training acc: 0.9999339580535889\n",
      "loss 0.0003129641991108656 Epoch: 9500  Training acc: 0.9999358654022217\n",
      "loss 0.00029040133813396096 Epoch: 9600  Training acc: 0.9999397993087769\n",
      "loss 0.00026952457847073674 Epoch: 9700  Training acc: 0.999957263469696\n",
      "loss 0.0002501259441487491 Epoch: 9800  Training acc: 0.999957263469696\n",
      "loss 0.00023205921752378345 Epoch: 9900  Training acc: 0.999963104724884\n",
      "loss 0.00021521009330172092 Epoch: 10000  Training acc: 0.999963104724884\n",
      "loss 0.0001994153280975297 Epoch: 10100  Training acc: 0.9999650716781616\n",
      "loss 0.0001845482038334012 Epoch: 10200  Training acc: 0.999968945980072\n",
      "loss 0.0001710810756776482 Epoch: 10300  Training acc: 0.999968945980072\n",
      "loss 0.0001586510188644752 Epoch: 10400  Training acc: 0.999968945980072\n",
      "loss 0.0001464634551666677 Epoch: 10500  Training acc: 0.9999708533287048\n",
      "loss 0.00013521304936148226 Epoch: 10600  Training acc: 0.9999728202819824\n",
      "loss 0.00012474015238694847 Epoch: 10700  Training acc: 0.9999728202819824\n",
      "loss 0.00011431111488491297 Epoch: 10800  Training acc: 0.9999728202819824\n",
      "loss 0.00010261782153975219 Epoch: 10900  Training acc: 0.9999728202819824\n",
      "loss 9.240936924470589e-05 Epoch: 11000  Training acc: 0.9999728202819824\n",
      "loss 8.325419912580401e-05 Epoch: 11100  Training acc: 0.9999728202819824\n",
      "loss 7.517813355661929e-05 Epoch: 11200  Training acc: 0.99997478723526\n",
      "loss 6.814001244492829e-05 Epoch: 11300  Training acc: 0.99997478723526\n",
      "loss 6.205333193065599e-05 Epoch: 11400  Training acc: 0.9999766945838928\n",
      "loss 5.6785200285958126e-05 Epoch: 11500  Training acc: 0.999980628490448\n",
      "loss 5.218774458626285e-05 Epoch: 11600  Training acc: 0.9999845027923584\n",
      "loss 4.810502287000418e-05 Epoch: 11700  Training acc: 0.9999903440475464\n",
      "loss 4.443847501534037e-05 Epoch: 11800  Training acc: 0.9999903440475464\n",
      "loss 4.102075399714522e-05 Epoch: 11900  Training acc: 0.9999903440475464\n",
      "loss 3.7903038901276886e-05 Epoch: 12000  Training acc: 0.9999922513961792\n",
      "loss 3.512599869281985e-05 Epoch: 12100  Training acc: 0.9999922513961792\n",
      "loss 3.26280714944005e-05 Epoch: 12200  Training acc: 0.9999922513961792\n",
      "loss 3.0338747819769196e-05 Epoch: 12300  Training acc: 0.9999922513961792\n",
      "loss 2.822760507115163e-05 Epoch: 12400  Training acc: 1.0\n",
      "loss 2.6251776944263838e-05 Epoch: 12500  Training acc: 1.0\n",
      "loss 2.4453196601825766e-05 Epoch: 12600  Training acc: 1.0\n",
      "loss 2.2791022274759598e-05 Epoch: 12700  Training acc: 1.0\n",
      "loss 2.1218520487309434e-05 Epoch: 12800  Training acc: 1.0\n",
      "loss 1.975620398297906e-05 Epoch: 12900  Training acc: 1.0\n",
      "loss 1.842292840592563e-05 Epoch: 13000  Training acc: 1.0\n",
      "loss 1.7193409803439863e-05 Epoch: 13100  Training acc: 1.0\n",
      "loss 1.6056650565587915e-05 Epoch: 13200  Training acc: 1.0\n",
      "loss 1.4997762264101766e-05 Epoch: 13300  Training acc: 1.0\n",
      "loss 1.4015384294907562e-05 Epoch: 13400  Training acc: 1.0\n",
      "loss 1.3097560440655798e-05 Epoch: 13500  Training acc: 1.0\n",
      "loss 1.2236499969731085e-05 Epoch: 13600  Training acc: 1.0\n",
      "loss 1.1431060556787997e-05 Epoch: 13700  Training acc: 1.0\n",
      "loss 1.0671336895029526e-05 Epoch: 13800  Training acc: 1.0\n",
      "loss 9.95893879007781e-06 Epoch: 13900  Training acc: 1.0\n",
      "loss 9.296779353462625e-06 Epoch: 14000  Training acc: 1.0\n",
      "loss 8.677714504301548e-06 Epoch: 14100  Training acc: 1.0\n",
      "loss 8.101870662358124e-06 Epoch: 14200  Training acc: 1.0\n",
      "loss 7.569266017526388e-06 Epoch: 14300  Training acc: 1.0\n",
      "loss 7.071586878737435e-06 Epoch: 14400  Training acc: 1.0\n",
      "loss 6.6072434492525645e-06 Epoch: 14500  Training acc: 1.0\n",
      "loss 6.1727300817437936e-06 Epoch: 14600  Training acc: 1.0\n",
      "loss 5.7660745369503275e-06 Epoch: 14700  Training acc: 1.0\n",
      "loss 5.386234988691285e-06 Epoch: 14800  Training acc: 1.0\n",
      "loss 5.031397449783981e-06 Epoch: 14900  Training acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "for epoch in range(9300,15000):\n",
    "    pred = model(G, node_features, edge_features)\n",
    "    loss = criterion(pred[train_mask], edge_label[train_mask])\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print('loss',loss.item(),'Epoch:', epoch ,' Training acc:', compute_accuracy(pred[train_mask], edge_label[train_mask]))\n",
    "    if epoch % 100 == 0:\n",
    "        torch.save(model.state_dict(), 'egat_bot_model' + str(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e88b6e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[115594      4      0      0      0]\n",
      " [     4  99012      0      0      0]\n",
      " [     2      0    279      5      0]\n",
      " [     0      0      8   5454      2]\n",
      " [     0      0      0      0     48]]\n"
     ]
    }
   ],
   "source": [
    "model = model.to('cpu')\n",
    "cm, cr = test(G_test, model)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e333b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9999    1.0000    1.0000    115598\n",
      "           1     1.0000    1.0000    1.0000     99016\n",
      "           2     0.9721    0.9755    0.9738       286\n",
      "           3     0.9991    0.9982    0.9986      5464\n",
      "           4     0.9600    1.0000    0.9796        48\n",
      "\n",
      "    accuracy                         0.9999    220412\n",
      "   macro avg     0.9862    0.9947    0.9904    220412\n",
      "weighted avg     0.9999    0.9999    0.9999    220412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8fd0f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07020eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(G_test, model):\n",
    "    test_node_features = G_test.ndata['h']\n",
    "    test_edge_features = G_test.edata['h']\n",
    "    y_true = G_test.edata['label'].detach().numpy()\n",
    "    pred = model(G_test, test_node_features, test_edge_features)\n",
    "    y_pred = pred.detach().numpy()\n",
    "    y_pred = np.argmax(y_pred, -1)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cr = classification_report(y_true, y_pred, digits=4)\n",
    "    return cm, cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8c3126e",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_test = load_graphs(\"./botlot/All features/bot_test_data_rus.bin\")[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8602eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_test.ndata['h'] = th.ones(G_test.num_nodes(), G_test.edata['h'].shape[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a95837c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 99016, 0: 115598, 3: 5464, 2: 286, 4: 48})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(G_test.edata['label'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeee24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, in_dim , out_dim):\n",
    "        super(GATLayer, self).__init__()\n",
    "        self.W = nn.Linear(in_dim, out_dim, bias=False)\n",
    "        self.attn_fc = nn.Linear(3 * out_dim, 1, bias=False)\n",
    "        self.reset_parameters()\n",
    "    def reset_parameters(self):\n",
    "        gain = nn.init.calculate_gain('relu')\n",
    "        nn.init.xavier_normal_(self.W.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.attn_fc.weight, gain=gain)\n",
    "    def edge_attention(self, edges):\n",
    "        z = torch.cat([edges.src['z'], edges.dst['z'], edges.data['z']], -1)\n",
    "        a = self.attn_fc(z)\n",
    "        alpha = F.leaky_relu(a)\n",
    "        return {'e': alpha}\n",
    "    def message_func(self, edges):\n",
    "        return {'z': edges.src['z'], 'e': edges.data['e'] ,'m': edges.data['z']}\n",
    "    def reduce_func(self, nodes):\n",
    "        alpha = F.softmax(nodes.mailbox['e'], dim=1) # 归一化每一条入边的注意力系数\n",
    "        h = torch.sum(alpha * nodes.mailbox['m'], dim=1)\n",
    "        return {'h': F.relu(h)}\n",
    "    def forward(self, g_dgl, hfeat, efeat):\n",
    "        with g_dgl.local_scope():\n",
    "            g = g_dgl\n",
    "            z1 = self.W(hfeat)\n",
    "            z2 = self.W(efeat)\n",
    "            g.ndata['z'] = z1 # 每个节点的特征\n",
    "            g.edata['z'] = z2 # 每条边的特征\n",
    "            g.apply_edges(self.edge_attention) # 为每一条边获得其注意力系数\n",
    "            g.update_all(self.message_func, self.reduce_func)\n",
    "            return g.ndata['h'], g.edata['z']\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.layer1 = GATLayer(in_dim, hidden_dim)\n",
    "        self.layer2 = GATLayer(hidden_dim, out_dim)\n",
    "        self.pred = MLPPredictor(out_dim, 5)\n",
    "    def forward(self, g, nfeats, efeats):\n",
    "        nfeats, efeats = self.layer1(g, nfeats, efeats)\n",
    "#         nfeats, efeats = self.layer2(g, nfeats, efeats)\n",
    "        return self.pred(g, nfeats)\n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, in_features, out_classes):\n",
    "        super().__init__()\n",
    "        self.W = nn.Linear(in_features * 2, out_classes)\n",
    "    def apply_edges(self, edges):\n",
    "        h_u = edges.src['h']\n",
    "        h_v = edges.dst['h']\n",
    "        score = self.W(th.cat([h_u, h_v], 1))\n",
    "        return {'score': score}\n",
    "    def forward(self, graph, h):\n",
    "        with graph.local_scope():\n",
    "            graph.ndata['h'] = h\n",
    "            graph.apply_edges(self.apply_edges)\n",
    "            return graph.edata['score']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
